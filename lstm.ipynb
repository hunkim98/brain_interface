{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "X_uncat = joblib.load('X_uncat.pkl')\n",
    "y = joblib.load('y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65034, 675, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_uncat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65034,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./mindbig_final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>device</th>\n",
       "      <th>channel</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>alpha_0</th>\n",
       "      <th>alpha_1</th>\n",
       "      <th>alpha_2</th>\n",
       "      <th>alpha_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sigma_125</th>\n",
       "      <th>sigma_126</th>\n",
       "      <th>sigma_127</th>\n",
       "      <th>sigma_128</th>\n",
       "      <th>sigma_129</th>\n",
       "      <th>sigma_130</th>\n",
       "      <th>sigma_131</th>\n",
       "      <th>sigma_132</th>\n",
       "      <th>sigma_133</th>\n",
       "      <th>sigma_134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67635</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>AF3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>0.319863</td>\n",
       "      <td>2.441277</td>\n",
       "      <td>8.833889</td>\n",
       "      <td>20.215495</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.958829</td>\n",
       "      <td>-25.521999</td>\n",
       "      <td>-37.618403</td>\n",
       "      <td>-48.813262</td>\n",
       "      <td>-58.610222</td>\n",
       "      <td>-66.487943</td>\n",
       "      <td>-71.946180</td>\n",
       "      <td>-74.557220</td>\n",
       "      <td>-74.016620</td>\n",
       "      <td>-70.186705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67636</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>F7</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>0.326693</td>\n",
       "      <td>2.493346</td>\n",
       "      <td>9.022391</td>\n",
       "      <td>20.648117</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.054094</td>\n",
       "      <td>-26.035788</td>\n",
       "      <td>-38.506702</td>\n",
       "      <td>-50.026377</td>\n",
       "      <td>-60.097178</td>\n",
       "      <td>-68.198218</td>\n",
       "      <td>-73.828418</td>\n",
       "      <td>-76.556006</td>\n",
       "      <td>-76.069798</td>\n",
       "      <td>-72.224948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67637</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>F3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>0.330275</td>\n",
       "      <td>2.520999</td>\n",
       "      <td>9.123475</td>\n",
       "      <td>20.880613</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.996782</td>\n",
       "      <td>-28.121353</td>\n",
       "      <td>-40.591954</td>\n",
       "      <td>-51.976920</td>\n",
       "      <td>-61.793656</td>\n",
       "      <td>-69.542278</td>\n",
       "      <td>-74.749714</td>\n",
       "      <td>-77.019742</td>\n",
       "      <td>-76.082220</td>\n",
       "      <td>-71.833860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67638</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>FC5</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>0.306204</td>\n",
       "      <td>2.337773</td>\n",
       "      <td>8.462327</td>\n",
       "      <td>19.371563</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.416258</td>\n",
       "      <td>-25.957415</td>\n",
       "      <td>-37.886198</td>\n",
       "      <td>-48.778552</td>\n",
       "      <td>-58.168924</td>\n",
       "      <td>-65.583350</td>\n",
       "      <td>-70.579782</td>\n",
       "      <td>-72.791892</td>\n",
       "      <td>-71.971329</td>\n",
       "      <td>-68.023447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67639</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>T7</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>0.327327</td>\n",
       "      <td>2.499235</td>\n",
       "      <td>9.047719</td>\n",
       "      <td>20.715055</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.066634</td>\n",
       "      <td>-25.760951</td>\n",
       "      <td>-37.926896</td>\n",
       "      <td>-49.151228</td>\n",
       "      <td>-58.963620</td>\n",
       "      <td>-66.871657</td>\n",
       "      <td>-72.403903</td>\n",
       "      <td>-75.156337</td>\n",
       "      <td>-74.837783</td>\n",
       "      <td>-71.309596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  event device channel  code  size   alpha_0   alpha_1   alpha_2  \\\n",
       "0  67635  67635     EP     AF3     6   260  0.319863  2.441277  8.833889   \n",
       "1  67636  67635     EP      F7     6   260  0.326693  2.493346  9.022391   \n",
       "2  67637  67635     EP      F3     6   260  0.330275  2.520999  9.123475   \n",
       "3  67638  67635     EP     FC5     6   260  0.306204  2.337773  8.462327   \n",
       "4  67639  67635     EP      T7     6   260  0.327327  2.499235  9.047719   \n",
       "\n",
       "     alpha_3  ...  sigma_125  sigma_126  sigma_127  sigma_128  sigma_129  \\\n",
       "0  20.215495  ... -12.958829 -25.521999 -37.618403 -48.813262 -58.610222   \n",
       "1  20.648117  ... -13.054094 -26.035788 -38.506702 -50.026377 -60.097178   \n",
       "2  20.880613  ... -14.996782 -28.121353 -40.591954 -51.976920 -61.793656   \n",
       "3  19.371563  ... -13.416258 -25.957415 -37.886198 -48.778552 -58.168924   \n",
       "4  20.715055  ... -13.066634 -25.760951 -37.926896 -49.151228 -58.963620   \n",
       "\n",
       "   sigma_130  sigma_131  sigma_132  sigma_133  sigma_134  \n",
       "0 -66.487943 -71.946180 -74.557220 -74.016620 -70.186705  \n",
       "1 -68.198218 -73.828418 -76.556006 -76.069798 -72.224948  \n",
       "2 -69.542278 -74.749714 -77.019742 -76.082220 -71.833860  \n",
       "3 -65.583350 -70.579782 -72.791892 -71.971329 -68.023447  \n",
       "4 -66.871657 -72.403903 -75.156337 -74.837783 -71.309596  \n",
       "\n",
       "[5 rows x 681 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_134\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "last_column = df.columns[-1]\n",
    "print(last_column)\n",
    "final_index = last_column.split('_')[-1]\n",
    "print(final_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'event', 'device', 'channel', 'code', 'size']\n"
     ]
    }
   ],
   "source": [
    "# our X should be size (N, 135, 14 * 4)\n",
    "alpha_columns = [f'alpha_{i}' for i in range(0, int(final_index) + 1)]\n",
    "beta_columns = [f'beta_{i}' for i in range(0, int(final_index) + 1)]\n",
    "theta_columns = [f'theta_{i}' for i in range(0, int(final_index) + 1)]\n",
    "delta_columns = [f'delta_{i}' for i in range(0, int(final_index) + 1)]\n",
    "sigma_columns = [f'sigma_{i}' for i in range(0, int(final_index) + 1)]\n",
    "\n",
    "# columns that are not the above\n",
    "other_columns = [col for col in df.columns if col not in alpha_columns and col not in beta_columns and col not in theta_columns and col not in delta_columns and col not in sigma_columns]\n",
    "\n",
    "print(other_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: (910476, 141) beta: (910476, 141) theta: (910476, 141) delta: (910476, 141) sigma: (910476, 141)\n",
      "['AF3' 'F7' 'F3' 'FC5' 'T7' 'P7' 'O1' 'O2' 'P8' 'T8' 'FC6' 'F4' 'F8' 'AF4']\n",
      "Shape of X: (65034, 135, 70)\n"
     ]
    }
   ],
   "source": [
    "# Define the base DataFrame and frequency bands\n",
    "base_df = df[other_columns]\n",
    "bands = {\n",
    "    \"alpha\": alpha_columns,\n",
    "    \"beta\": beta_columns,\n",
    "    \"theta\": theta_columns,\n",
    "    \"delta\": delta_columns,\n",
    "    \"sigma\": sigma_columns\n",
    "}\n",
    "\n",
    "# Create DataFrames for each frequency band\n",
    "band_dfs = {band: base_df.join(df[columns]) for band, columns in bands.items()}\n",
    "\n",
    "# Print shapes of the band DataFrames\n",
    "print(*(f\"{band}: {band_dfs[band].shape}\" for band in bands))\n",
    "\n",
    "# Extract unique channels\n",
    "channels = base_df[\"channel\"].unique()\n",
    "print(channels)\n",
    "\n",
    "# Extract data for each band and channel into a dictionary\n",
    "band_channel_data = {\n",
    "    band: {\n",
    "        channel: band_dfs[band][band_dfs[band][\"channel\"] == channel][columns].values\n",
    "        for channel in channels\n",
    "    }\n",
    "    for band, columns in bands.items()\n",
    "}\n",
    "\n",
    "seq_length = 135\n",
    "\n",
    "# Create a 3D tensor with shape (N, seq_length, 14 * 5)\n",
    "X = np.concatenate(\n",
    "    [\n",
    "        np.stack([band_channel_data[band][channel] for channel in channels], axis=-1)\n",
    "        for band in bands\n",
    "    ],\n",
    "    axis=-1\n",
    ")\n",
    "\n",
    "# Reshape to ensure the sequence length is seq_length\n",
    "X = X[:, :seq_length, :]  # Truncate or pad if necessary to match seq_length\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65034, 135, 70) (65034,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n",
      "(52027, 135, 70) (52027,) (13007, 135, 70) (13007,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# apple gpu \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "    device = mps_device\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train = X_train.transpose(0, 2, 1)\n",
    "# X_test = X_test.transpose(0, 2, 1)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Define the PyTorch model\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, channels=14, n_classes=11):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(channels)  # Channels should match input shape\n",
    "        self.conv1 = nn.Conv1d(channels, 128, kernel_size=10, stride=1, padding='same')\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=256, batch_first=True)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Switch to (batch, channels, sequence)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)  # Reorder for LSTM (batch, sequence, input_size)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.batch_norm3(x[:, -1, :])  # Use the last LSTM output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 28\u001b[0m     val_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m criterion(val_outputs, y_train_tensor)\n\u001b[1;32m     30\u001b[0m     _, val_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(val_outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Github/studio-brain/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/studio-brain/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[24], line 54\u001b[0m, in \u001b[0;36mEEGNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     53\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Switch to (batch, channels, sequence)\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[1;32m     56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norm2(x)\n",
      "File \u001b[0;32m~/Github/studio-brain/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/studio-brain/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Github/studio-brain/.venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/studio-brain/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = EEGNet(channels=70, n_classes=11).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping criteria\n",
    "best_accuracy = 0\n",
    "patience = 10\n",
    "trigger_times = 0\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X.to(device))\n",
    "        loss = criterion(outputs, batch_Y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_train_tensor.to(device))\n",
    "        val_loss = criterion(val_outputs, y_train_tensor.to(device))\n",
    "        _, val_preds = torch.max(val_outputs, 1)\n",
    "        val_accuracy = accuracy_score(y_train_tensor.cpu().numpy(), val_preds.cpu().numpy())\n",
    "        print(f\"Epoch {epoch+1}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
